{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown Cell 1: Explanation\n",
    "In the cell below, we import the necessary libraries.\n",
    "\n",
    "random is used for generating random selections based on weighted probabilities.\n",
    "defaultdict from the collections module allows us to handle missing keys in our trigram model efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Third-Order Letter Approximation Model\n",
    "\n",
    "In this Task, we will load five English books, clean their text, and build a trigram model from the cleaned text. A trigram model counts the occurrences of each sequence of three consecutive characters in the text, allowing us to analyze the structure of the language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Books\n",
    "\n",
    "In this step, I will initialize an empty list to store the contents of five books. I will iterate through the list of book file paths, opening each file in read mode with UTF-8 encoding to read the text. By the end, all five books will be stored in the list, preparing for the next steps of text cleaning and trigram model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books(file_paths):\n",
    "    texts = []  # Initialize an empty list to store the content of each book\n",
    "    for file_path in file_paths:  # Loop through each file path in the list\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:  # Open the file in read mode with UTF-8 encoding\n",
    "            texts.append(f.read())  # Read the entire content and append it to the texts list\n",
    "    return texts  # Return the list of all loaded books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of file paths to the books stored in the 'texts' folder\n",
    "file_paths = ['texts/book1.txt', 'texts/book2.txt', 'texts/book3.txt', 'texts/book4.txt', 'texts/book5.txt']\n",
    "books = load_books(file_paths)  # Call the load_books function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean Text\n",
    "\n",
    "In this step, we will clean the text from each book to ensure that we only retain uppercase letters, spaces, and full stops. This process will help us in building an accurate trigram model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.upper()  # Convert the text to uppercase\n",
    "    # Keep only letters, spaces, and full stops\n",
    "    cleaned_text = ''.join([char for char in text if char.isalpha() or char == ' ' or char == '.'])\n",
    "    return cleaned_text  # Return the cleaned text\n",
    "\n",
    "# Clean each book\n",
    "cleaned_books = [clean_text(book) for book in books]  # Apply the clean_text function to all books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Trigram Model\n",
    "\n",
    "Here, we will construct a trigram model from the cleaned text. The model will count the occurrences of each sequence of three consecutive characters. This will allow us to analyze the character structure of the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigram_model(text):\n",
    "    trigram_model = defaultdict(int)  # Create a defaultdict to store trigram counts\n",
    "    for i in range(len(text) - 2):  # Iterate through the text, leaving space for the last two characters\n",
    "        trigram = text[i:i+3]  # Extract a trigram (3 characters)\n",
    "        trigram_model[trigram] += 1  # Increment the count for this trigram in the model\n",
    "    return trigram_model  # Return the trigram model\n",
    "\n",
    "# Initialize a combined trigram model to accumulate counts from all books\n",
    "trigram_model = defaultdict(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each cleaned book to build the trigram model for that book\n",
    "for book in cleaned_books:\n",
    "    book_trigram_model = build_trigram_model(book)  # Build the trigram model for the current book\n",
    "    # Merge the current book's trigram model with the overall model\n",
    "    for trigram, count in book_trigram_model.items():\n",
    "        trigram_model[trigram] += count  # Add the count of this trigram to the overall model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Output the Trigram Model\n",
    "\n",
    "Finally, we will display a sample of the trigram model to verify that it has been constructed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram: \"THE\", Count: 22365\n",
      "Trigram: \"HE \", Count: 20954\n",
      "Trigram: \"E P\", Count: 1892\n",
      "Trigram: \" PR\", Count: 1947\n",
      "Trigram: \"PRO\", Count: 1493\n",
      "Trigram: \"ROJ\", Count: 444\n",
      "Trigram: \"OJE\", Count: 445\n",
      "Trigram: \"JEC\", Count: 541\n",
      "Trigram: \"ECT\", Count: 1409\n",
      "Trigram: \"CT \", Count: 759\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 trigrams and their counts\n",
    "for i, (trigram, count) in enumerate(trigram_model.items()):\n",
    "    if i < 10:  # Limit output to the first 10 trigrams\n",
    "        print(f'Trigram: \"{trigram}\", Count: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Third-Order Letter Approximation Generation\n",
    "In this task, we will generate a string of 10,000 characters using the trigram model created in Task 1. We will start with the string \"TH\" and generate each subsequent character based on the preceding two characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the Function to Generate the Next Character\n",
    "We first define a function, generate_character(), which takes the last two characters of the generated string and uses the trigram model to determine the next character. This function finds all trigrams that start with those two characters and then randomly selects one of the possible third characters, using the trigram counts as weights for the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the next character based on the last two characters using the trigram model\n",
    "def generate_character(last_two, trigram_model):\n",
    "    # Find trigrams that start with the last two characters\n",
    "    candidates = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "    \n",
    "    # Calculate the total count of possible next characters\n",
    "    total_count = sum(candidates.values())\n",
    "    \n",
    "    # Choose the next character randomly, weighted by the counts of the trigrams\n",
    "    r = random.randint(1, total_count)\n",
    "    cumulative_count = 0\n",
    "    for trigram, count in candidates.items():\n",
    "        cumulative_count += count\n",
    "        if cumulative_count >= r:\n",
    "            return trigram[-1]  # Return the third character of the trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Generated Text\n",
    "Now I initialize the text generation by starting with the string \"TH\", as per the instructions. This will serve as the seed for the next characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generated text with the seed 'TH'\n",
    "generated_text = \"TH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate 10,000 Characters\n",
    "Using a loop, I will now generate the remaining 9,998 characters (since we already have 2 characters in \"TH\"). For each new character, we pass the last two characters to generate_character() to determine the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10,000 characters using the trigram model\n",
    "for _ in range(9998):  #I need 9998 more characters to reach 10,000\n",
    "    last_two = generated_text[-2:]  # Get the last two characters from the generated text\n",
    "    next_char = generate_character(last_two, trigram_model)  # Generate the next character\n",
    "    generated_text += next_char  # Append the generated character to the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Output and Save the Generated Text\n",
    "Finally, after generating the full text, I display a sample of the first 500 characters for verification and save the entire generated text to a file for future analysis or inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THED SOMOUTTHER CIPPRET INT ON LOURNIALL WALREVEREMPURIT PRODYTHOWN BROCOMTHERY FOUN DED I WHOUTINAR.SHOM SHRE GED NOF MENHE HEALOND OF THE RETED HINGERS LEYES A GO THAN HE LIS SO. TO TO HE READESSLY DER BEGRE WHOLL ACQUE CAN EYWOUTERWAS THLECT THEPROJECT TOSED FROVE HE AND YOUTER MOT TH YOU WIT NOTHE NOTROWER PER SHERGELLOR PEN HADCOVEDGING JOURE CROJECALAT WE MR. HANCENBEY TO THE EARD ANNEASS ABIT.WHORNE BRA. CRIAMED WITIOD LAINDEMPS AN THE CRALAMED FECROGETTHE A SH A HEING BUTTER. IFIRTHER WI\n"
     ]
    }
   ],
   "source": [
    "# Output the first 500 characters of the generated text for verification\n",
    "print(generated_text[:500])\n",
    "\n",
    "# Save the generated text to a file for future reference\n",
    "with open('generated_text.txt', 'w') as f:\n",
    "    f.write(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 1697\n"
     ]
    }
   ],
   "source": [
    "# Split the generated text into words and count them\n",
    "word_count = len(generated_text.split())  \n",
    "# Print the word count to the console\n",
    "print(f\"Word count: {word_count}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3. Analyze your model\n",
    "\n",
    "In this task, we will analyze the trigram-based text generation model to determine how many words from the generated text are actual English words. We will use the `words.txt` file, which contains a list of valid English words, and compare it with the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load English Words from words.txt\n",
    "In this step, I will load the list of English words from the words.txt file. This file contains a comprehensive list of valid English words, which we will use to compare against the words generated in Task 2. The words will be stored in a set for fast lookup operations when checking if a word is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        words = f.read().splitlines()  # Read the file and split it into a list of words\n",
    "    return set(words)  # Return a set for fast lookup\n",
    "\n",
    "# Load the words list from 'words.txt'\n",
    "english_words = load_words('words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the Generated Text into Words\n",
    "Here, I will split the generated text from Task 2 into individual words. Since the generated text is a continuous string, we will use spaces as the delimiter to separate the words. This will allow us to compare the resulting words with the valid English words loaded from words.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_words(text):\n",
    "    return text.split()\n",
    "\n",
    "# Split the generated text into words\n",
    "generated_words = split_text_into_words(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Count Valid Words in the Generated Text\n",
    "After splitting the generated text into words, this will count how many of those words are valid English words. I will iterate through the list of generated words and check if each word exists in the set of English words. This will give me a count of valid words, which I can use to evaluate the performance of the trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_words(generated_words, english_words):\n",
    "    valid_word_count = 0\n",
    "    for word in generated_words:\n",
    "        if word in english_words:  # Check if the word exists in the English words set\n",
    "            valid_word_count += 1\n",
    "    return valid_word_count\n",
    "\n",
    "# Count how many words from generated text are valid English words\n",
    "valid_word_count = count_valid_words(generated_words, english_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze and Explain the Results\n",
    "Finally, we will explain and interpret the results of our analysis. Based on the percentage of valid words, we will reflect on how well the trigram model performs and suggest any potential improvements or insights. The higher the percentage, the more accurate the model is in generating real English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 1697\n",
      "Valid English words: 589\n",
      "Percentage of valid words: 34.71%\n"
     ]
    }
   ],
   "source": [
    "total_words = len(generated_words)  # Total number of generated words\n",
    "valid_word_percentage = (valid_word_count / total_words) * 100  # Calculate the percentage\n",
    "\n",
    "print(f\"Total words: {total_words}\")\n",
    "print(f\"Valid English words: {valid_word_count}\")hbhb\n",
    "print(f\"Percentage of valid words: {valid_word_percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
